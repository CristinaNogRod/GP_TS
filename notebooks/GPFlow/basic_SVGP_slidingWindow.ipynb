{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gpflow.utilities import print_summary, set_trainable, to_default_float\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "from data_preparation import get_birth_data, separate_data, train_test_normalise\n",
    "from useful_fun import plot_sliding_window, number_outof_CI, split_dataframe_by_position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "# whole dataset\n",
    "data = get_birth_data()\n",
    "x, y = separate_data(data) # y is unnormalised: good!\n",
    "\n",
    "# get date for x-axis in plots: mm-yyyy\n",
    "def get_xticks(df):\n",
    "    dff = df.groupby(by='m-y').first()\n",
    "    pos = dff.ids; pos = pos[1:]\n",
    "    labels = dff.index; labels = labels[1:]\n",
    "    return pos, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding Window\n",
    "### Simple one-latent function model with SVGP\n",
    "\n",
    "        y = f(x) + e\n",
    "        f = GP(0, RBF)\n",
    "\n",
    "        l = InvGama()\n",
    "        sigma = Gamma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_model(model, x_train, y_train):\n",
    "    train_data = (x_train, y_train)\n",
    "    loss_fn = model.training_loss_closure(train_data) \n",
    "\n",
    "    gpflow.utilities.set_trainable(model.q_mu, False)\n",
    "    gpflow.utilities.set_trainable(model.q_sqrt, False)\n",
    "\n",
    "    variational_vars = [(model.q_mu, model.q_sqrt)]\n",
    "    natgrad_opt = gpflow.optimizers.NaturalGradient(gamma=0.1)\n",
    "    adam_vars = model.trainable_variables\n",
    "    adam_opt = tf.optimizers.Adam(0.01)\n",
    "\n",
    "    @tf.function\n",
    "    def optimisation_step():\n",
    "        natgrad_opt.minimize(loss_fn, variational_vars)\n",
    "        adam_opt.minimize(loss_fn, adam_vars)\n",
    "\n",
    "    epochs = 50\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        optimisation_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try first train on 10months predict on 2months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations to go through, plot:  116 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 22:13:30.860846: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "splits = 121 # two month split\n",
    "split_dataframes = split_dataframe_by_position(data, splits)\n",
    "\n",
    "# evaluation lists\n",
    "ELBO_train = []\n",
    "mse_train = []; mae_train = []; n_outof_CI_train = []\n",
    "mse_test = [];  mae_test = [];  n_outof_CI_test = []\n",
    "\n",
    "# window sizes\n",
    "window_size = 5 # 5 for 10months\n",
    "iterations = splits-window_size\n",
    "\n",
    "# which iteration to plot\n",
    "iteration_plot = np.random.randint(low=0, high=iterations)\n",
    "print('iterations to go through, plot: ', iterations, iteration_plot)\n",
    "\n",
    "for i in range(splits-window_size):\n",
    "    # create new dataframe\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # select data\n",
    "    for df_ind in range(window_size):\n",
    "        if df_ind == 0:\n",
    "            df = split_dataframes[i]\n",
    "        else :\n",
    "            df = pd.concat([df, split_dataframes[i+df_ind]], axis=0)\n",
    "\n",
    "    whole_data = pd.concat([df, split_dataframes[i+window_size]], axis=0)\n",
    "    pos, labels = get_xticks(whole_data)\n",
    "\n",
    "    # normalise & separate data\n",
    "    df_train = df; df_test = split_dataframes[i+window_size]\n",
    "    df_train, df_test = train_test_normalise(df_train, df_test)\n",
    "    x_train, y_train = separate_data(df_train)\n",
    "    x_test, y_test = separate_data(df_test)\n",
    "\n",
    "    # number of inducing points\n",
    "    M = int(0.7 * x_train.shape[0])\n",
    "    \n",
    "    # build model\n",
    "    kernel = gpflow.kernels.RBF(lengthscales = 1, variance = 1)\n",
    "    #Z = x_train.numpy().copy()\n",
    "    Z = np.linspace(x_train.numpy().min(), x_train.numpy().max(), M)[:, None]\n",
    "    model = gpflow.models.SVGP(kernel, gpflow.likelihoods.Gaussian(), Z, mean_function=gpflow.mean_functions.Zero(), num_data=M)\n",
    "    set_trainable(model.likelihood.variance, False)\n",
    "    model.kernel.lengthscales.prior = tfp.distributions.InverseGamma(to_default_float(0.5), to_default_float(1))\n",
    "    model.kernel.variance.prior = tfp.distributions.Gamma(to_default_float(2), to_default_float(3))\n",
    "\n",
    "    # optimise\n",
    "    optimise_model(model, x_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    mean_train, var_train = model.predict_f(x_train)\n",
    "    mean_test, var_test = model.predict_f(x_test)\n",
    "\n",
    "    # evaluate\n",
    "    ELBO_train.append(model.elbo((x_train,y_train)).numpy())\n",
    "    mse_train.append(mean_squared_error(y_train, mean_train)); mae_train.append(mean_absolute_error(y_train, mean_train)); n_outof_CI_train.append(number_outof_CI(y_train, mean_train, var_train))\n",
    "    mse_test.append(mean_squared_error(y_test, mean_test)); mae_test.append(mean_absolute_error(y_test, mean_test)); n_outof_CI_test.append(number_outof_CI(y_test, mean_test, var_test))\n",
    "\n",
    "    if i == iteration_plot:\n",
    "        plot_sliding_window(x_train, x_test, y_train, y_test, mean_train, mean_test, var_train, var_test, pos, labels, iteration=1)\n",
    "    \n",
    "\n",
    "# Average evaluation metrics\n",
    "print('ELBO Avg: ', np.mean(ELBO_train))\n",
    "print('Train Avg. MSE, MAE, points outside CI: ', np.mean(mse_train), np.mean(mae_train), np.mean(n_outof_CI_train))\n",
    "print('Test Avg. MSE, MAE, points outside CI: ', np.mean(mse_test), np.mean(mae_test), np.mean(n_outof_CI_test))\n",
    "\n",
    "# histogram of CI\n",
    "fig, ax = plt.subplots(1,2, figsize=(7,10))\n",
    "ax[0].hist(n_outof_CI_train, bins=50)\n",
    "ax[0].set_title('Train')\n",
    "ax[1].hist(n_outof_CI_test, bins=50)\n",
    "ax[1].set_title('Test')\n",
    "plt.title('Histogram of number of points that lie outside CI')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = 60 # 4 month split\n",
    "split_dataframes = split_dataframe_by_position(data, splits)\n",
    "\n",
    "# evaluation lists\n",
    "ELBO_train = []\n",
    "mse_train = []; mae_train = []; n_outof_CI_train = []\n",
    "mse_test = [];  mae_test = [];  n_outof_CI_test = []\n",
    "\n",
    "# window sizes\n",
    "window_size =  # 5 for 10months\n",
    "iterations = splits-window_size\n",
    "\n",
    "# which iteration to plot\n",
    "iteration_plot = np.random.randint(low=0, high=iterations)\n",
    "print(iteration_plot)\n",
    "\n",
    "# number of inducing points\n",
    "M = None\n",
    "\n",
    "for i in range(splits-window_size):\n",
    "    print('iterations to go through: ', iterations)\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # select data\n",
    "    for df_ind in range(window_size):\n",
    "        if df_ind == 0:\n",
    "            df = split_dataframes[i]\n",
    "        else :\n",
    "            df = pd.concat([df, split_dataframes[i+df_ind]], axis=0)\n",
    "\n",
    "    whole_data = pd.concat([df, split_dataframes[i+window_size]], axis=0)\n",
    "    pos, labels = get_xticks(whole_data)\n",
    "\n",
    "    # normalise & separate data\n",
    "    df_train = df; df_test = split_dataframes[i+window_size]\n",
    "    df_train, df_test = train_test_normalise(df_train, df_test)\n",
    "    x_train, y_train = separate_data(df_train)\n",
    "    x_test, y_test = separate_data(df_test)\n",
    "    \n",
    "    # build model\n",
    "    kernel = gpflow.kernels.RBF(lengthscales = 1, variance = 1)\n",
    "    Z = x_train.numpy().copy()\n",
    "    # Z = np.linspace(x_train.numpy().min(), x_train.numpy().max(), M)[:, None]\n",
    "    model = gpflow.models.SVGP(kernel, gpflow.likelihoods.Gaussian(), Z, mean_function=gpflow.mean_functions.Zero(), num_data=M)\n",
    "    set_trainable(model.likelihood.variance, False)\n",
    "    model.kernel.lengthscales.prior = tfp.distributions.InverseGamma(to_default_float(0.5), to_default_float(1))\n",
    "    model.kernel.variance.prior = tfp.distributions.Gamma(to_default_float(2), to_default_float(3))\n",
    "\n",
    "    # optimise\n",
    "    optimise_model(model, x_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    mean_train, var_train = model.predict_f(x_train)\n",
    "    mean_test, var_test = model.predict_f(x_test)\n",
    "\n",
    "    # evaluate\n",
    "    ELBO_train.append(model.elbo((x_train,y_train)).numpy())\n",
    "    mse_train.append(mean_squared_error(y_train, mean_train)); mae_train.append(mean_absolute_error(y_train, mean_train)); n_outof_CI_train.append(number_outof_CI(y_train, mean_train, var_train))\n",
    "    mse_test.append(mean_squared_error(y_test, mean_test)); mae_test.append(mean_absolute_error(y_test, mean_test)); n_outof_CI_test.append(number_outof_CI(y_test, mean_test, var_test))\n",
    "\n",
    "    if i == iteration_plot:\n",
    "        plot_sliding_window(x_train, x_test, y_train, y_test, mean_train, mean_test, var_train, var_test, pos, labels, iteration=1)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
